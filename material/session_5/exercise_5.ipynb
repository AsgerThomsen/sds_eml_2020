{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise set 4: the generalized random forest\n",
    "\n",
    "In this exercise set we will be working with the [generalized random forest](https://github.com/grf-labs/grf) by Athey et al. The package is written for the R programming language, and while there is a R-to-python interface in [rpy2](https://rpy2.bitbucket.io/) it can be tricky to get working. If you run into trouble, you can consider saving your data to a csv file and work directly in [R](https://www.r-project.org/) through [Rstudio](https://rstudio.com/products/rstudio/download/). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To highlight the usefulness of GRF we will be working with synthetic data in this exercise. In particular we will synthetically add a treatment effect to a dataset in which there otherwise is none. Furthermore we will make this effect heterogeneous by adding noise, and by making it depend on a single continuous variable as well as a categorical variable. \n",
    "\n",
    ">**Ex. 4.1.1:** Complete the code below to simulate data according to\n",
    "$$\n",
    "T = U(0,1) > 0.5 \\\\ \n",
    "Y(T=0) = X\\beta + \\epsilon \\\\ \n",
    "\\tau(X) =  \\begin{cases}\n",
    "        \\frac{10}{1 + e^{-\\gamma X_0}} + \\nu & D = 0\\\\ \n",
    "        \\nu & D = 1\n",
    "        \\end{cases}\\\\ \n",
    "Y(T=1) = Y(0) + \\tau(X) \\\\ \n",
    "$$\n",
    "where $\\epsilon, \\nu$ are simply noise terms distributed according to $\\mathcal{N}(0,1)$ and $\\beta$ is an `N_FEATURES` vector of random parameters. $\\gamma$ is a scalar parameter.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_SAMPLES = 10000\n",
    "N_FEATURES = 5\n",
    "GAMMA = 3\n",
    "BETA = np.random.uniform(0,1, size = N_FEATURES)\n",
    "\n",
    "X = np.random.normal(size = (N_SAMPLES, N_FEATURES))\n",
    "D = np.random.choice([0,1], size = N_SAMPLES)\n",
    "\n",
    "Y0 = X @ BETA + np.random.normal()\n",
    "Tau = # FILL IN \n",
    "Y1 = # FILL IN\n",
    "y = # FILL IN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ex. 4.1.2:** Create a two-subplot figure, and plot $Y(0)$ and $Y(1)$ in one subplot against $X_0$. Plot $\\tau(x)$ against $X_0$ in the other subplot. What do you see? Why do we observe $\\tau=0$ in many cases?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Ex 4.1.3.** Import `statsmodels` and estimate a simple linear regression\n",
    "$$\n",
    "y = \\alpha + \\delta_0 T + \\sum_k \\beta_k X_k + \\epsilon\n",
    "$$\n",
    ">What is your estimate of $\\hat{\\delta}_0$? How does this number fit with the figures you drew in the previous exercise? Do you have any suggestions for improving the estimate of the model, comment on whether your improvements would provide unbiased estimates of $\\tau$? \n",
    ">\n",
    "> **Bonus:** fit your improved model, and relate the parameters you estimate to the figure you plotted in the previous question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Ex. 4.1.4:** For this question we will need to move into R (or use rpy2). If you are working in python you can skip this step, otherwise do the following. \n",
    ">\n",
    "> Save a dataframe, containing $X$, $y$, $T$, and $D$ as a csv file on your computer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Ex. 4.1.5:** Open up R and read the data you just saved into a dataframe(or work in rpy2). Install and load the two libraries `tidyverse` and `grf`.\n",
    ">\n",
    "> _Hint:_ to install the required packages. run this:\n",
    "> ```R\n",
    "> install.packages(\"tidyverse\")\n",
    "> install.packages(\"grf\")\n",
    "> ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer either here, or in R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Ex. 4.1.5:** Copy the following code into R to split your dataframe into two matrices, `X`, and `y`. Implement the exact same procedure to create a third matrix `W` which contains the treatment indicator (**Note** `T` is a reserved name in R, so name your third matrix `W`).\n",
    ">```R\n",
    ">X <- df %>%\n",
    "  select(X0, X1, X2, X3, X4, D) %>% \n",
    "  as.matrix()\n",
    ">\n",
    ">y <- df %>%\n",
    "  select(y) %>% \n",
    "  as.matrix()\n",
    ">```\n",
    "> Finally spend some time poking around the [GRF documentation](https://github.com/grf-labs/grf). See if you can figure out how to estimate a GRF model, once you have the three matrices you need (this is way simpler than you might expect)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer either here, or in R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Ex.4.1.6:** Estimate a causal forest model using the GRF package, and store the result in a new variable `cf`. Then use the following line to create a dataframe of predicted treatment effects on the same data that you trained the model on. \n",
    ">```R\n",
    ">cf <- # Estimate a generalized RF model aimed at treatment effects.\n",
    ">tau <- predict(cf, X)\n",
    ">```\n",
    "> Once you have your individual treatment effects, run the following line, to save them in a csv file. \n",
    "> ```R\n",
    "> write.csv(tau, \"individual_treatment_effects.csv\")\n",
    "> ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer either here, or in R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Ex.4.1.6:** This concludes our venture into R. Now load the treatment effects into a pandas dataframe, and plot a scatterplot of the estimated individual treatment effects against the simulated \"true\" ITE's `Tau` that you produced in the beginning of this exercise set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer either here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
