{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "# Session 5:\n",
    "## Growing Causal Trees \n",
    "### - *Causal Forests and Generalized Random Forests*\n",
    "\n",
    "*Andreas Bjerre-Nielsen*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Agenda\n",
    "\n",
    "1. Growing causal trees\n",
    "  - [Recap on Random Forest](Recap-on-Random-Forest)\n",
    "  - [Causal Forest](#Causal-Forest)\n",
    "  - [Generalized Random Forest](#Generalized-Random-Forest) (GRF)\n",
    "1. Applying GRF \n",
    "  - [In-class research: heterogeneous treatment effects](#In-class-research:-heterogeneous-treatment-effects)\n",
    "  - [Using R within Python](Using-R-within-Python)\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Recap on Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The  forest full of trees\n",
    "\n",
    "What is the difference between a Decision Tree and a Random Forest?\n",
    "\n",
    "- \n",
    "- \n",
    "- \n",
    "\n",
    "<center><img src='https://p1.pxfuel.com/preview/386/193/136/forest-of-rugen-trees-beech-wood-nature-deciduous-forest-rest-national-park.jpg' alt=\"Drawing\" style=\"width: 680px;\"/></center>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "\n",
    "## A special tree \n",
    "\n",
    "So what distinguishes a Causal Tree from a Decision Tree?\n",
    "\n",
    "- \n",
    "- \n",
    "- \n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "<center><img src='https://live.staticflickr.com/2880/33000342484_8681f68a01_b.jpg' alt=\"Drawing\" style=\"width: 600px;\"/></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## A tradeoff in structure of heterogeneity\n",
    "\n",
    "\n",
    "Two approaches? \n",
    "\n",
    "- Data driven heterogeneity\n",
    "  - ..\n",
    "- A priori sensible heterogeneity \n",
    "  - e.g. gender, socioeconomic, ethnicity\n",
    "  - ..\n",
    "\n",
    "When to choose which?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Limitations of Decision Trees \n",
    "\n",
    "\n",
    "Random forests are nice but no asymptotic normality of prediction.\n",
    "\n",
    "- Crucial for inference! (corresponds to MLR6 in Econometrics 1)\n",
    "\n",
    "- Also holds for causal trees\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Random forest for inference and treatment effecs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Causal  Trees\n",
    "\n",
    "The goal of causal trees is to establish unbiased, consistent estimates of heterogeneous treatment effects\n",
    "- also known as conditional average treatment effects (**CATE**)\n",
    "- the effect size is denoted $\\hat{\\tau}(x)$;\n",
    "- standard tools for inference, e.g. using statistical tests locally\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Causal Forest \n",
    "\n",
    "What is the output from the decisions trees? Each tree produces a partitioning of the feature space $X$. Example of three trees:\n",
    "\n",
    "<center><img src='partitions.JPG' alt=\"Drawing\" style=\"width: 1000px;\"/></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Double Sample Trees \n",
    "\n",
    "For Causal Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- first half ($\\mathcal{J}$, $|\\mathcal{J}|=\\lceil s / 2\\rceil$)\n",
    "  - training Decision Tree\n",
    "    - minimize adjusted MSE \n",
    "    - require at least $k$ observations for both treatment and control in all leaves of $\\mathcal{I}$-sample\n",
    "- other half  ($\\mathcal{I}$, $|\\mathcal{I}|=\\lfloor s / 2\\rfloor$)\n",
    "  - estimating treatment effects, $\\hat{\\tau}(x)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Double Sample Trees (2)\n",
    "\n",
    "For Regression Trees "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- first half ($\\mathcal{J}$, $|\\mathcal{J}|=\\lceil s / 2\\rceil$)\n",
    "  - training Decision Tree\n",
    "    - minimize MSE / Gini etc.\n",
    "    - require at least $k$ observations in all leaves of $\\mathcal{I}$-sample\n",
    "- other half  ($\\mathcal{I}$, $|\\mathcal{I}|=\\lfloor s / 2\\rfloor$)\n",
    "  - estimating outcome, $\\hat{\\mu}(x)$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Quiz:** How is this different from normal Decision Trees for regression problems?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\n",
    "- Unlike normal decision trees outcomes are estimated honestly.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Main results: econometric properties (1)\n",
    "\n",
    "\n",
    "\n",
    "[Wager and Athey (2017)](https://doi.org/10.1080/01621459.2017.1319839) show \n",
    " - We can estimate the variance of CATE\n",
    " - $\\hat{V}_{IJ}(x)=\\frac{n-1}{n}\\left(\\frac{n}{n-s}\\right)^{2} \\sum_{i=1}^{n} \\operatorname{Cov}_{*}\\left[\\hat{\\tau}_{b}^{*}(x), N_{i b}^{*}\\right]^{2}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Main results: econometric properties (2)\n",
    "\n",
    "From Theorem 4.1 in [Wager and Athey (2017)](https://doi.org/10.1080/01621459.2017.1319839)\n",
    "\n",
    "- The conditional average treatment estimates are unbiased and consistent\n",
    "  - unbiased: no systematic error of measurement\n",
    "  - consistency: with more data our estimate approaches true value "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Moreover, we can do inference:\n",
    "  - The variance estimator $\\hat{V}_{IJ}(x)$ is consistent.\n",
    "  - Treatment effect estimates are asymptotic normal and unbiased\n",
    "    - $(\\hat{\\tau}(x)-\\tau(x)) / \\sqrt{\\operatorname{Var}[\\hat{\\tau}(x)]} \\Rightarrow \\mathcal{N}(0,1)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Caveat: only works for evaluating treatment effects in one point $x$! Do not perform multiple tests."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Useful forests\n",
    "\n",
    "Two more procedures\n",
    "\n",
    "1. Double Sampled Trees\n",
    "  - using Regression trees for predicting outcome (=$\\hat{\\mu}(x)$)\n",
    "1. Propensity Trees\n",
    "  -  using propensity trees for propensity score matching\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "What is the shared procedure? \n",
    "- Each tree is estimated using repeated subsampling (**no replacement**)\n",
    "  - Constrast to bootstrap aggregation in random forest (sample **with replacment**)\n",
    "- Random subsample of features  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## More results \n",
    "\n",
    "[Wager and Athey (2017)](https://doi.org/10.1080/01621459.2017.1319839) show that the same properties of Double Sample Trees using causal trees also hold analogously for regression trees. \n",
    "- Random forests  have the property of being asymptotic normal and can thus be used for inference\n",
    "- Similar intuition as idea of nested CV where we could do inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Simulation experiment\n",
    "\n",
    "[Wager,  and Athey (2017)](https://doi.org/10.1214/18-aos1709) compare causal forest to nearest neighbor methods \n",
    "- random forest is kind of local nearest neighbor estimate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Simulation (1) \n",
    "\n",
    "- simulation setup: no treatment effect, only confounding factors\n",
    "- method: propensity trees \n",
    "- comparison of estimated treatment effects  \n",
    "    - lower MSE and better coverage\n",
    "    - coverage falls for increasing number of variables $d$\n",
    "\n",
    "<center><img src='cf_tab1.JPG' alt=\"Drawing\" style=\"width: 700px;\"/></center>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Simulation (2) \n",
    "\n",
    "- setup: heterogeneous treatment effect, **no** confounding factors\n",
    "\n",
    "- comparison of estimated treatment effects\n",
    "    - lower MSE and better coverage\n",
    "    - coverage falls for increasing number of variables $d$\n",
    "\n",
    "<center><img src='cf_tab2.JPG' alt=\"Drawing\" style=\"width: 700px;\"/></center>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Meta learners for heterogeneous treatment effects \n",
    "\n",
    "Other procedures have been investigated\n",
    "\n",
    "- [Künzel et al. (2019)](https://doi.org/10.1073/pnas.1804597116) investigates more general class of prediction tools for partitioning data using \n",
    "\n",
    "  - Lower EMSE in many cases relative to causal forest and BART (Bayesian tree based method)\n",
    "  \n",
    "- [Nie and Wager (2017)](https://arxiv.org/pdf/1712.04912.pdf) investigates another class of methods called R-learners that leverages a smart representation of CATE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Round-up causal forest\n",
    "\n",
    "Summary of [Wager and Athey (2017)](https://doi.org/10.1080/01621459.2017.1319839) \n",
    "- builds on Causal Trees method\n",
    "- strong econometric properties\n",
    "  - unbiased and consistent\n",
    "  - asymptotic normality given $x$\n",
    "      - causal and regression forest allows inference!\n",
    "- problem: \n",
    "  - must choose focus \n",
    "    - unconfounding (propensity) or \n",
    "    - estimate CATE\n",
    "  - coverage was not good, especially for higher $d$!\n",
    "  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Generalized Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## A higher aim\n",
    "\n",
    "Causal forests are pretty cool. Can we use our honest procedure more generally? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Estimate any quantity $\\theta(x)$ identified via local moment conditions, e.g.\n",
    "  - simultaneously unconfound and find heterogeneity?\n",
    "  - find heterogeneous treatment effects from IV estimation?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Different purpose\n",
    "\n",
    "How does this look?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The general moment conditions\n",
    "    - $\\mathbb{E}\\left[\\psi_{\\theta(x), \\nu(x)}\\left(O_{i}\\right) | X_{i}=x\\right]=0, \\quad \\forall x.$\n",
    "    \n",
    "- Where $\\psi$  estimating function, maps parameters and data into moment equations\n",
    "  - Parameters\n",
    "    - $\\theta$ parameter we want estimate \n",
    "    - $\\nu$ is nuisance we want to \"partial out\"\n",
    "  - Data     \n",
    "    - $O_i$ main objects we are interested in modelling, e.g. $Y_i, D_i$\n",
    "    - $X_i$ covariates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Different purpose (2)\n",
    "\n",
    "What is a moment condition?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Similiar to solution to first order condition\n",
    "- More general - can incorporate extra restrictions (e.g. unconfounding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Different purpose (3)\n",
    "\n",
    "Suppose we want to estimate treatment effects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Functional form: $\\psi_{\\beta(x),c(x)}=Y_i-\\beta(x)W_i-c(x)$ where\n",
    "  - $\\beta$ is treatment effect\n",
    "  - $c$ is nuisance parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Using a kernel\n",
    "\n",
    "Kernel methods can be used to unconfound and compute heterogeneous effects simulateneously\n",
    "\n",
    "\n",
    "- Problem how to decide weights?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\n",
    "<center><img src='partitions_weights.JPG' alt=\"Drawing\" style=\"width: 1000px;\"/></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The Generalized Random Forest\n",
    "\n",
    "[Athey, Wager, Tibshirani (2019)](https://doi.org/10.1214/18-aos1709) show that kernel weights can be estimated using forest methods\n",
    "\n",
    "- can be adapted for different purposes\n",
    "  - quantile regression\n",
    "  - heterogeneous treatment effects\n",
    "  - instrumental variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The Generalized Random Forest (2)\n",
    "\n",
    "[Athey, Wager, Tibshirani (2019)](https://doi.org/10.1214/18-aos1709) use a procedure as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Use estimating equation, $\\psi$ to estimate tree splits iteratively on subsample. \n",
    "2. View forests as a weights of similar neighbors\n",
    "    - Amount of partitions where observations \n",
    "  \\begin{equation}\\alpha_i(x)=\\frac{1}{B}\\sum_{b=1}\\frac{\\mathbb{1}(X_i\\in L_b(X)}{|L_b(x)|}\\end{equation}\n",
    "3. Re-estimate $\\psi$ using weights on entire sample.\n",
    "\n",
    "Difference from Causal Forest - trees are used for constructing weights!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# In-class research: heterogeneous treatment effects\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The student as a researcher\n",
    "\n",
    "We will try to make a collaborative effort in doing a research project. \n",
    "\n",
    "The primary goal is to learn how to apply the methods. Our effort may turn into research.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The task\n",
    "\n",
    "Work alone or in pairs.\n",
    "\n",
    "1. Find a research paper that runs an experiment, either field or lab. Requirements for paper:\n",
    "  - There are is at least one or more covariates for each treated unit (e.g. gender if individuals).\n",
    "  - There is experimental data is available. You may look in the dataverse at Harvard or papers from experimental economics etc.\n",
    "1. Make a function that loads and structure the data in Python. The output should contain:\n",
    "  - Outcomes, $y$ a vector with $n$-observations \n",
    "  - Treatments, $D$ a vector with $n$-observations with $0,1$  \n",
    "  - Covariates, $X$ a matrix with $n\\times k$ dimensions\n",
    "1. Try to replicate the results in terms of computing ATE or ATT.\n",
    "1. Use `grf` to compute average treatment effects and heterogeneous treatment effects.\n",
    "  - Hint: you can use the `grf` tutorial [here](https://grf-labs.github.io/grf/articles/grf.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Using R within Python\n",
    "## Leveraging the rpy2 package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Installing R in Anaconda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "!conda install -c r rpy2 -y\n",
    "!conda install -c r r-irkernel -y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Import R in python\n",
    "\n",
    "If the code below fails, check out the guidance on adding PATH variables [for Linux or Mac](https://stackoverflow.com/questions/51486081/install-and-use-rpy2-using-conda-so-that-it-uses-default-r-installation-in-us) and [for Windows](https://anaconda.zendesk.com/hc/en-us/articles/360023857134-Setting-up-rpy2-on-Windows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import rpy2\n",
    "import rpy2.robjects as robjects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Installing R from Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# import rpy2's package module\n",
    "import rpy2.robjects.packages as rpackages\n",
    "\n",
    "# import R's utility package\n",
    "utils = rpackages.importr('utils')\n",
    "\n",
    "# select a mirror for R packages\n",
    "utils.chooseCRANmirror(ind=1) # select the first mirror in the list\n",
    "\n",
    "# R package names\n",
    "packnames = ('ggplot2', 'hexbin', 'grf')\n",
    "\n",
    "# R vector of strings\n",
    "from rpy2.robjects.vectors import StrVector\n",
    "\n",
    "# Selectively install what needs to be install.\n",
    "# We are fancy, just because we can.\n",
    "names_to_install = [x for x in packnames if not rpackages.isinstalled(x)]\n",
    "if len(names_to_install) > 0:\n",
    "    utils.install_packages(StrVector(names_to_install))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Importing R package from Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from rpy2.robjects.packages import importr\n",
    "grf = importr('grf')"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
